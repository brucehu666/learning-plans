# No004-神经网络基础：理解深度学习的核心

## 1. 神经网络基础概述

神经网络是深度学习的核心组成部分，它模拟了人脑神经元的工作方式，通过层层计算来解决复杂的模式识别和预测问题。本教程将带你深入了解神经网络的基本结构、工作原理和训练方法。

## 2. 神经网络的基本结构

### 理论知识点
神经网络由以下基本组件构成：

1. **神经元（Neuron）**：神经网络的基本计算单元，接收输入信号，进行加权求和，然后通过激活函数产生输出
2. **权重（Weights）**：连接神经元的参数，决定输入信号的重要性
3. **偏置（Bias）**：调节神经元输出的常数项
4. **激活函数（Activation Function）**：引入非线性特性，使网络能够学习复杂模式
5. **层（Layers）**：神经元的集合，分为输入层、隐藏层和输出层

### 实践示例：手动实现简单神经元

```python
# 手动实现简单神经元

import numpy as np

class Neuron:
    def __init__(self, input_size):
        # 初始化权重和偏置
        self.weights = np.random.randn(input_size)  # 随机初始化权重
        self.bias = np.random.randn()  # 随机初始化偏置
    
    def sigmoid(self, x):
        # sigmoid激活函数
        return 1 / (1 + np.exp(-x))
    
    def forward(self, inputs):
        # 前向传播计算
        # 加权和 + 偏置
        weighted_sum = np.dot(inputs, self.weights) + self.bias
        # 通过激活函数
        output = self.sigmoid(weighted_sum)
        return output

# 测试简单神经元
if __name__ == "__main__":
    # 创建一个有3个输入的神经元
    neuron = Neuron(3)
    
    # 测试不同的输入
    inputs1 = np.array([0.5, 0.3, 0.8])
    inputs2 = np.array([-0.2, 1.0, -0.5])
    
    output1 = neuron.forward(inputs1)
    output2 = neuron.forward(inputs2)
    
    print(f"神经元权重: {neuron.weights}")
    print(f"神经元偏置: {neuron.bias}")
    print(f"输入 {inputs1} 的输出: {output1}")
    print(f"输入 {inputs2} 的输出: {output2}")
```

## 3. 常见的激活函数

### 理论知识点
激活函数在神经网络中扮演着至关重要的角色，它们引入非线性特性，使网络能够学习复杂的函数关系。常见的激活函数包括：

1. **Sigmoid**：将输入映射到(0,1)区间，公式：σ(x) = 1/(1+e^-x)
2. **Tanh**：将输入映射到(-1,1)区间，公式：tanh(x) = (e^x - e^-x)/(e^x + e^-x)
3. **ReLU**：修正线性单元，公式：ReLU(x) = max(0, x)
4. **Leaky ReLU**：ReLU的变体，避免神经元死亡问题，公式：Leaky ReLU(x) = max(αx, x)，其中α通常为0.01
5. **Softmax**：常用于多分类问题的输出层，将原始分数转换为概率分布

### 实践示例：可视化常见激活函数

```python
# 可视化常见激活函数

import numpy as np
import matplotlib.pyplot as plt

# 设置中文显示
plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]
plt.rcParams["axes.unicode_minus"] = False

# 定义激活函数
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def tanh(x):
    return np.tanh(x)

def relu(x):
    return np.maximum(0, x)

def leaky_relu(x, alpha=0.01):
    return np.maximum(alpha * x, x)

def softmax(x):
    exp_x = np.exp(x - np.max(x))  # 防止数值溢出
    return exp_x / np.sum(exp_x, axis=0)

# 生成输入数据
x = np.linspace(-5, 5, 100)

# 创建图形
plt.figure(figsize=(12, 10))

# 绘制Sigmoid
plt.subplot(2, 3, 1)
plt.plot(x, sigmoid(x))
plt.title('Sigmoid函数')
plt.grid(True)

# 绘制Tanh
plt.subplot(2, 3, 2)
plt.plot(x, tanh(x))
plt.title('Tanh函数')
plt.grid(True)

# 绘制ReLU
plt.subplot(2, 3, 3)
plt.plot(x, relu(x))
plt.title('ReLU函数')
plt.grid(True)

# 绘制Leaky ReLU
plt.subplot(2, 3, 4)
plt.plot(x, leaky_relu(x))
plt.title('Leaky ReLU函数')
plt.grid(True)

# 绘制Softmax (用于多分类的输出层)
x_softmax = np.array([[-2, 0, 3], [-1, 1, 2], [0, 2, 1]])
plt.subplot(2, 3, 5)
for i in range(x_softmax.shape[0]):
    plt.plot(range(len(x_softmax[i])), softmax(x_softmax[i]), 'o-', label=f'样本{i+1}')
plt.title('Softmax函数(多分类)')
plt.grid(True)
plt.legend()

# 调整布局
plt.tight_layout()
plt.show()
```

## 4. 前向传播和反向传播

### 理论知识点
神经网络的训练过程包括两个主要步骤：前向传播和反向传播。

1. **前向传播（Forward Propagation）**：
   - 输入数据从输入层流向输出层
   - 每层神经元计算加权和并通过激活函数
   - 最终在输出层产生预测结果

2. **反向传播（Backpropagation）**：
   - 计算预测值与实际值之间的损失
   - 从输出层开始，计算损失对每个参数的梯度
   - 使用梯度下降算法更新权重和偏置
   - 重复此过程直到模型收敛

### 实践示例：手动实现简单的前向传播和反向传播

```python
# 手动实现简单的前向传播和反向传播

import numpy as np
import matplotlib.pyplot as plt

# 设置中文显示
plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]
plt.rcParams["axes.unicode_minus"] = False

class SimpleNN:
    def __init__(self, input_size, hidden_size, output_size):
        # 初始化权重和偏置
        self.W1 = np.random.randn(input_size, hidden_size)  # 输入层到隐藏层的权重
        self.b1 = np.zeros((1, hidden_size))               # 隐藏层的偏置
        self.W2 = np.random.randn(hidden_size, output_size) # 隐藏层到输出层的权重
        self.b2 = np.zeros((1, output_size))               # 输出层的偏置
        
    def relu(self, x):
        return np.maximum(0, x)
    
    def relu_derivative(self, x):
        return np.where(x > 0, 1, 0)
    
    def forward(self, X):
        # 前向传播
        self.z1 = np.dot(X, self.W1) + self.b1
        self.a1 = self.relu(self.z1)
        self.z2 = np.dot(self.a1, self.W2) + self.b2
        self.a2 = self.z2  # 输出层不使用激活函数（回归问题）
        return self.a2
    
    def compute_loss(self, y_pred, y_true):
        # 均方误差损失
        return np.mean((y_pred - y_true) ** 2)
    
    def backward(self, X, y_true, learning_rate=0.01):
        # 计算样本数量
        m = X.shape[0]
        
        # 计算输出层的梯度
        dz2 = self.a2 - y_true
        dW2 = np.dot(self.a1.T, dz2) / m
        db2 = np.sum(dz2, axis=0, keepdims=True) / m
        
        # 计算隐藏层的梯度
        dz1 = np.dot(dz2, self.W2.T) * self.relu_derivative(self.z1)
        dW1 = np.dot(X.T, dz1) / m
        db1 = np.sum(dz1, axis=0, keepdims=True) / m
        
        # 更新权重和偏置
        self.W1 -= learning_rate * dW1
        self.b1 -= learning_rate * db1
        self.W2 -= learning_rate * dW2
        self.b2 -= learning_rate * db2

# 创建样本数据用于训练
X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # 输入
# 创建一个稍微复杂的目标函数: y = x1^2 + x2^2
# 这里我们添加一些噪声使其更接近真实世界的数据
y = np.array([[0.1], [1.1], [1.2], [2.1]])  # 目标值

# 创建并训练模型
model = SimpleNN(input_size=2, hidden_size=5, output_size=1)

# 训练模型
epochs = 10000
learning_rate = 0.01
losses = []

for epoch in range(epochs):
    # 前向传播
    y_pred = model.forward(X)
    
    # 计算损失
    loss = model.compute_loss(y_pred, y)
    losses.append(loss)
    
    # 反向传播和参数更新
    model.backward(X, y, learning_rate)
    
    # 每1000个epoch打印一次损失
    if (epoch + 1) % 1000 == 0:
        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss:.4f}')

# 测试模型
print("\n模型预测结果:")
for i in range(len(X)):
    print(f'输入: {X[i]}, 预测输出: {model.forward(X[i].reshape(1, -1))[0][0]:.4f}, 实际输出: {y[i][0]}')

# 可视化损失曲线
plt.figure(figsize=(10, 6))
plt.plot(range(epochs), losses)
plt.title('训练损失曲线')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True)
plt.show()
```

## 5. 梯度下降及其变体

### 理论知识点
梯度下降是神经网络训练的核心算法，它通过不断调整权重和偏置来最小化损失函数。常见的梯度下降变体包括：

1. **批量梯度下降（Batch Gradient Descent）**：
   - 使用整个训练集计算梯度
   - 收敛稳定，但计算成本高

2. **随机梯度下降（Stochastic Gradient Descent，SGD）**：
   - 每次只使用一个样本计算梯度
   - 计算速度快，但收敛不稳定

3. **小批量梯度下降（Mini-Batch Gradient Descent）**：
   - 结合前两者的优点，使用一部分样本计算梯度
   - 平衡了计算效率和收敛稳定性

4. **动量法（Momentum）**：
   - 累积之前的梯度，加速收敛
   - 减少震荡，帮助逃离局部最小值

5. **Adam优化器**：
   - 结合动量法和自适应学习率
   - 适用于大多数场景，收敛速度快

### 实践示例：不同梯度下降算法的比较

```python
# 比较不同梯度下降算法的性能

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

# 设置中文显示
plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]
plt.rcParams["axes.unicode_minus"] = False

# 生成合成数据集
X, y = make_regression(n_samples=1000, n_features=10, noise=10, random_state=42)

y = y.reshape(-1, 1)  # 重塑目标值

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 转换为PyTorch张量
X_train_tensor = torch.FloatTensor(X_train)
y_train_tensor = torch.FloatTensor(y_train)
X_test_tensor = torch.FloatTensor(X_test)
y_test_tensor = torch.FloatTensor(y_test)

# 创建数据加载器
batch_size = 32
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

# 定义神经网络模型
class RegressionModel(nn.Module):
    def __init__(self, input_size):
        super(RegressionModel, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.relu = nn.ReLU()
    
    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# 训练函数
def train_model(model, optimizer, train_loader, epochs=100):
    criterion = nn.MSELoss()
    train_losses = []
    
    for epoch in range(epochs):
        running_loss = 0.0
        for inputs, targets in train_loader:
            # 前向传播
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            
            # 反向传播和优化
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item() * inputs.size(0)
        
        # 计算 epoch 损失
        epoch_loss = running_loss / len(train_loader.dataset)
        train_losses.append(epoch_loss)
        
        # 每10个epoch打印一次
        if (epoch + 1) % 10 == 0:
            print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}')
    
    return train_losses

# 创建模型和优化器进行比较
input_size = X_train.shape[1]
results = {}

# 1. SGD优化器
print("\n使用SGD优化器:")
model_sgd = RegressionModel(input_size)
optimizer_sgd = optim.SGD(model_sgd.parameters(), lr=0.001)
losses_sgd = train_model(model_sgd, optimizer_sgd, train_loader)
results['SGD'] = losses_sgd

# 2. SGD with Momentum
print("\n使用带动量的SGD优化器:")
model_momentum = RegressionModel(input_size)
optimizer_momentum = optim.SGD(model_momentum.parameters(), lr=0.001, momentum=0.9)
losses_momentum = train_model(model_momentum, optimizer_momentum, train_loader)
results['SGD with Momentum'] = losses_momentum

# 3. Adam优化器
print("\n使用Adam优化器:")
model_adam = RegressionModel(input_size)
optimizer_adam = optim.Adam(model_adam.parameters(), lr=0.001)
losses_adam = train_model(model_adam, optimizer_adam, train_loader)
results['Adam'] = losses_adam

# 可视化不同优化器的性能
plt.figure(figsize=(12, 8))
for name, losses in results.items():
    plt.plot(range(1, len(losses) + 1), losses, label=name)

plt.title('不同优化器的训练损失对比')
plt.xlabel('Epoch')
plt.ylabel('MSE Loss')
plt.grid(True)
plt.legend()
plt.show()

# 评估模型在测试集上的性能
def evaluate_model(model, X_test, y_test):
    model.eval()
    with torch.no_grad():
        outputs = model(X_test)
        mse = nn.MSELoss()(outputs, y_test)
        return mse.item()

# 评估所有模型
print("\n模型在测试集上的MSE损失:")
print(f'SGD: {evaluate_model(model_sgd, X_test_tensor, y_test_tensor):.4f}')
print(f'SGD with Momentum: {evaluate_model(model_momentum, X_test_tensor, y_test_tensor):.4f}')
print(f'Adam: {evaluate_model(model_adam, X_test_tensor, y_test_tensor):.4f}')
```

## 6. 神经网络架构类型

### 理论知识点
根据不同的任务需求，神经网络有多种架构类型，常见的包括：

1. **前馈神经网络（Feedforward Neural Network，FNN）**：
   - 最简单的神经网络架构
   - 信息从输入层单向流向输出层
   - 适用于简单的分类和回归问题

2. **卷积神经网络（Convolutional Neural Network，CNN）**：
   - 特别适合处理图像和空间数据
   - 使用卷积层提取局部特征
   - 包含池化层进行降维和特征抽象

3. **循环神经网络（Recurrent Neural Network，RNN）**：
   - 适合处理序列数据，如文本、语音
   - 包含反馈连接，能够记住之前的信息
   - 变种包括LSTM和GRU，解决了长序列依赖问题

4. **生成对抗网络（Generative Adversarial Network，GAN）**：
   - 由生成器和判别器两个网络组成
   - 通过对抗训练生成逼真的数据
   - 用于图像生成、风格转换等

5. **Transformer**：
   - 基于自注意力机制的架构
   - 在自然语言处理任务中取得了突破性进展
   - 代表模型有BERT、GPT等

### 实践示例：使用PyTorch实现简单的CNN

```python
# 使用PyTorch实现简单的CNN

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np

# 设置中文显示
plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]
plt.rcParams["axes.unicode_minus"] = False

# 定义转换
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# 加载MNIST数据集
trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)
testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)

# 定义CNN模型
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        # 卷积层1
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        # 池化层1
        self.pool = nn.MaxPool2d(2, 2)
        # 卷积层2
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        # 全连接层1
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        # 全连接层2（输出层）
        self.fc2 = nn.Linear(128, 10)
        # ReLU激活函数
        self.relu = nn.ReLU()
        # Dropout层（防止过拟合）
        self.dropout = nn.Dropout(0.5)
    
    def forward(self, x):
        # 卷积层1 -> ReLU -> 池化
        x = self.pool(self.relu(self.conv1(x)))
        # 卷积层2 -> ReLU -> 池化
        x = self.pool(self.relu(self.conv2(x)))
        # 展平
        x = x.view(-1, 64 * 7 * 7)
        # 全连接层1 -> ReLU -> Dropout
        x = self.dropout(self.relu(self.fc1(x)))
        # 输出层
        x = self.fc2(x)
        return x

# 创建模型、损失函数和优化器
model = SimpleCNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 训练模型
def train_model(model, trainloader, criterion, optimizer, epochs=5):
    for epoch in range(epochs):
        running_loss = 0.0
        
        for i, data in enumerate(trainloader, 0):
            # 获取输入和标签
            inputs, labels = data
            
            # 梯度清零
            optimizer.zero_grad()
            
            # 前向传播
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            
            # 反向传播和优化
            loss.backward()
            optimizer.step()
            
            # 统计损失
            running_loss += loss.item()
            if i % 100 == 99:
                print(f'Epoch [{epoch+1}/{epochs}], Batch [{i+1}/{len(trainloader)}], Loss: {running_loss/100:.3f}')
                running_loss = 0.0
    
    print('训练完成')

# 测试模型
def test_model(model, testloader):
    model.eval()  # 设置为评估模式
    correct = 0
    total = 0
    
    with torch.no_grad():
        for data in testloader:
            images, labels = data
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    
    print(f'测试集准确率: {100 * correct / total:.2f}%')

# 可视化预测结果
def visualize_predictions(model, testloader, num_samples=5):
    model.eval()
    images, labels = next(iter(testloader))
    outputs = model(images[:num_samples])
    _, predicted = torch.max(outputs, 1)
    
    plt.figure(figsize=(10, 5))
    for i in range(num_samples):
        plt.subplot(1, num_samples, i+1)
        plt.imshow(images[i].numpy().squeeze(), cmap='gray')
        plt.title(f'预测: {predicted[i].item()}\n实际: {labels[i].item()}')
        plt.axis('off')
    plt.tight_layout()
    plt.show()

# 执行训练和测试
if __name__ == "__main__":
    # 如果有GPU可用，使用GPU
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    model.to(device)
    
    # 调整数据加载器以使用GPU
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)
    testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)
    
    # 训练模型
    print("开始训练模型...")
    train_model(model, trainloader, criterion, optimizer, epochs=3)
    
    # 测试模型
    print("测试模型性能...")
    test_model(model, testloader)
    
    # 可视化预测结果
    print("可视化预测结果...")
    visualize_predictions(model, testloader)
```

## 7. 神经网络调优技巧

### 理论知识点
训练有效的神经网络需要掌握一些关键的调优技巧：

1. **超参数调优**：
   - 学习率：过小会导致收敛慢，过大会导致不稳定
   - 批量大小：影响训练速度和稳定性
   - 网络深度和宽度：过深或过宽可能导致过拟合

2. **防止过拟合**：
   - 数据增强：增加训练数据的多样性
   - Dropout：训练过程中随机失活部分神经元
   - L1/L2正则化：限制权重大小
   - 早停：监控验证损失，适时停止训练

3. **数据预处理**：
   - 归一化/标准化：使输入数据分布一致
   - 特征工程：选择和转换适合模型的特征

### 实践示例：使用早停防止过拟合

```python
# 使用早停防止过拟合

import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification
from sklearn.preprocessing import StandardScaler

# 设置中文显示
plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]
plt.rcParams["axes.unicode_minus"] = False

# 生成合成数据集
X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)

# 数据预处理
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

y = y.reshape(-1, 1)

# 划分训练集、验证集和测试集
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# 转换为PyTorch张量
X_train_tensor = torch.FloatTensor(X_train)
y_train_tensor = torch.FloatTensor(y_train)
X_val_tensor = torch.FloatTensor(X_val)
y_val_tensor = torch.FloatTensor(y_val)
X_test_tensor = torch.FloatTensor(X_test)
y_test_tensor = torch.FloatTensor(y_test)

# 创建数据加载器
batch_size = 32
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_dataset = TensorDataset(X_val_tensor, y_val_tensor)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

# 定义神经网络模型
class ClassifierModel(nn.Module):
    def __init__(self, input_size):
        super(ClassifierModel, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 32)
        self.fc4 = nn.Linear(32, 1)
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)
    
    def forward(self, x):
        x = self.dropout(self.relu(self.fc1(x)))
        x = self.dropout(self.relu(self.fc2(x)))
        x = self.dropout(self.relu(self.fc3(x)))
        x = self.sigmoid(self.fc4(x))
        return x

# 定义早停机制
class EarlyStopping:
    def __init__(self, patience=5, verbose=False):
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf
    
    def __call__(self, val_loss, model):
        score = -val_loss
        
        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score:
            self.counter += 1
            if self.verbose:
                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0
    
    def save_checkpoint(self, val_loss, model):
        if self.verbose:
            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...')
        torch.save(model.state_dict(), 'checkpoint_model.pt')
        self.val_loss_min = val_loss

# 创建模型、损失函数和优化器
input_size = X_train.shape[1]
model = ClassifierModel(input_size)
criterion = nn.BCELoss()  # 二元交叉熵损失
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 初始化早停对象
early_stopping = EarlyStopping(patience=10, verbose=True)

# 训练模型
epochs = 200
train_losses = []
val_losses = []

for epoch in range(epochs):
    # 训练模式
    model.train()
    train_loss = 0.0
    
    for inputs, labels in train_loader:
        # 梯度清零
        optimizer.zero_grad()
        
        # 前向传播
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        
        # 反向传播和优化
        loss.backward()
        optimizer.step()
        
        # 累加损失
        train_loss += loss.item() * inputs.size(0)
    
    # 计算训练损失
    train_loss /= len(train_loader.dataset)
    train_losses.append(train_loss)
    
    # 评估模式
    model.eval()
    val_loss = 0.0
    
    with torch.no_grad():
        for inputs, labels in val_loader:
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * inputs.size(0)
    
    # 计算验证损失
    val_loss /= len(val_loader.dataset)
    val_losses.append(val_loss)
    
    # 打印epoch信息
    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}')
    
    # 早停检查
    early_stopping(val_loss, model)
    
    if early_stopping.early_stop:
        print("早停触发，停止训练")
        break

# 加载最佳模型
best_model = ClassifierModel(input_size)
best_model.load_state_dict(torch.load('checkpoint_model.pt'))

# 评估模型在测试集上的性能
best_model.eval()
with torch.no_grad():
    test_outputs = best_model(X_test_tensor)
    test_loss = criterion(test_outputs, y_test_tensor)
    
    # 计算准确率
    test_preds = (test_outputs >= 0.5).float()
    test_acc = (test_preds == y_test_tensor).sum().item() / len(y_test_tensor)
    
    print(f'\n测试损失: {test_loss:.6f}, 测试准确率: {test_acc:.4f}')

# 可视化训练和验证损失曲线
plt.figure(figsize=(10, 6))
plt.plot(range(1, len(train_losses) + 1), train_losses, 'b-', label='训练损失')
plt.plot(range(1, len(val_losses) + 1), val_losses, 'r-', label='验证损失')
plt.title('训练和验证损失曲线')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True)
plt.legend()
plt.show()
```

## 8. 总结与下一步

通过本教程，你学习了神经网络的基础知识，包括：
- 神经网络的基本结构和组件
- 常见的激活函数及其特性
- 前向传播和反向传播的工作原理
- 不同的梯度下降算法及其比较
- 常见的神经网络架构类型
- 神经网络调优的关键技巧

这些知识将帮助你理解深度学习模型的工作原理，并为后续的实践应用打下坚实的基础。

**下一步**：请继续学习**No005-预训练模型基础.md**，了解如何使用现有的预训练模型进行迁移学习，以及如何在自己的项目中应用这些强大的模型。